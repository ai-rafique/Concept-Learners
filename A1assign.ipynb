{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Authors\n",
    "- Muhammad Ahmad Imran Rafique\n",
    "- Syed Saif Ahmed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [],
   "source": [
    "# The required modules are imported.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for data preprocessing\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "fb47a9c4",
   "metadata": {},
   "source": [
    "# Loading the dataset\n",
    "As per spam base description, we have 58 columns where the first 57 are the explanatory variables or features and the last column is\n",
    "the response variable or spam(1) or ham(0). As such, we will load the dataset split.\n",
    "The explanatory variables are continuous with last three columns being somewhat whole numbers or int64. the 54/57 columns are float64 type except the last 3 but numpy will automatically typecast the datatype to the largest kind. (e.g 10 rows, 9 are int64, 1 is float64, all 10 will become float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d94b6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "loading and splitting spam base dataset into explanatory/response or X,y\n",
    "\"\"\"\n",
    "dataset = pd.read_csv(\"Data\\spambase.data\",header=None)\n",
    "X = dataset.iloc[:,:-1].values # .values converts panda df to numpy\n",
    "y= dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4601 non-null   float64\n",
      " 1   1       4601 non-null   float64\n",
      " 2   2       4601 non-null   float64\n",
      " 3   3       4601 non-null   float64\n",
      " 4   4       4601 non-null   float64\n",
      " 5   5       4601 non-null   float64\n",
      " 6   6       4601 non-null   float64\n",
      " 7   7       4601 non-null   float64\n",
      " 8   8       4601 non-null   float64\n",
      " 9   9       4601 non-null   float64\n",
      " 10  10      4601 non-null   float64\n",
      " 11  11      4601 non-null   float64\n",
      " 12  12      4601 non-null   float64\n",
      " 13  13      4601 non-null   float64\n",
      " 14  14      4601 non-null   float64\n",
      " 15  15      4601 non-null   float64\n",
      " 16  16      4601 non-null   float64\n",
      " 17  17      4601 non-null   float64\n",
      " 18  18      4601 non-null   float64\n",
      " 19  19      4601 non-null   float64\n",
      " 20  20      4601 non-null   float64\n",
      " 21  21      4601 non-null   float64\n",
      " 22  22      4601 non-null   float64\n",
      " 23  23      4601 non-null   float64\n",
      " 24  24      4601 non-null   float64\n",
      " 25  25      4601 non-null   float64\n",
      " 26  26      4601 non-null   float64\n",
      " 27  27      4601 non-null   float64\n",
      " 28  28      4601 non-null   float64\n",
      " 29  29      4601 non-null   float64\n",
      " 30  30      4601 non-null   float64\n",
      " 31  31      4601 non-null   float64\n",
      " 32  32      4601 non-null   float64\n",
      " 33  33      4601 non-null   float64\n",
      " 34  34      4601 non-null   float64\n",
      " 35  35      4601 non-null   float64\n",
      " 36  36      4601 non-null   float64\n",
      " 37  37      4601 non-null   float64\n",
      " 38  38      4601 non-null   float64\n",
      " 39  39      4601 non-null   float64\n",
      " 40  40      4601 non-null   float64\n",
      " 41  41      4601 non-null   float64\n",
      " 42  42      4601 non-null   float64\n",
      " 43  43      4601 non-null   float64\n",
      " 44  44      4601 non-null   float64\n",
      " 45  45      4601 non-null   float64\n",
      " 46  46      4601 non-null   float64\n",
      " 47  47      4601 non-null   float64\n",
      " 48  48      4601 non-null   float64\n",
      " 49  49      4601 non-null   float64\n",
      " 50  50      4601 non-null   float64\n",
      " 51  51      4601 non-null   float64\n",
      " 52  52      4601 non-null   float64\n",
      " 53  53      4601 non-null   float64\n",
      " 54  54      4601 non-null   float64\n",
      " 55  55      4601 non-null   int64  \n",
      " 56  56      4601 non-null   int64  \n",
      " 57  57      4601 non-null   int64  \n",
      "dtypes: float64(55), int64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \nmean      0.104553     0.213015     0.280656     0.065425     0.312223   \nstd       0.305358     1.290575     0.504143     1.395151     0.672513   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.000000     0.420000     0.000000     0.380000   \nmax       4.540000    14.280000     5.100000    42.810000    10.000000   \n\n                5            6            7            8            9   ...  \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000  ...   \nmean      0.095901     0.114208     0.105295     0.090067     0.239413  ...   \nstd       0.273824     0.391441     0.401071     0.278616     0.644755  ...   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \nmax       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n\n                48           49           50           51           52  \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \nmean      0.038575     0.139030     0.016976     0.269071     0.075811   \nstd       0.243471     0.270355     0.109394     0.815672     0.245882   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n75%       0.000000     0.188000     0.000000     0.315000     0.052000   \nmax       4.385000     9.752000     4.081000    32.478000     6.003000   \n\n                53           54           55            56           57  \ncount  4601.000000  4601.000000  4601.000000   4601.000000  4601.000000  \nmean      0.044238     5.191515    52.172789    283.289285     0.394045  \nstd       0.429342    31.729449   194.891310    606.347851     0.488698  \nmin       0.000000     1.000000     1.000000      1.000000     0.000000  \n25%       0.000000     1.588000     6.000000     35.000000     0.000000  \n50%       0.000000     2.276000    15.000000     95.000000     0.000000  \n75%       0.000000     3.706000    43.000000    266.000000     1.000000  \nmax      19.829000  1102.500000  9989.000000  15841.000000     1.000000  \n\n[8 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n      <th>57</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>...</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.104553</td>\n      <td>0.213015</td>\n      <td>0.280656</td>\n      <td>0.065425</td>\n      <td>0.312223</td>\n      <td>0.095901</td>\n      <td>0.114208</td>\n      <td>0.105295</td>\n      <td>0.090067</td>\n      <td>0.239413</td>\n      <td>...</td>\n      <td>0.038575</td>\n      <td>0.139030</td>\n      <td>0.016976</td>\n      <td>0.269071</td>\n      <td>0.075811</td>\n      <td>0.044238</td>\n      <td>5.191515</td>\n      <td>52.172789</td>\n      <td>283.289285</td>\n      <td>0.394045</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.305358</td>\n      <td>1.290575</td>\n      <td>0.504143</td>\n      <td>1.395151</td>\n      <td>0.672513</td>\n      <td>0.273824</td>\n      <td>0.391441</td>\n      <td>0.401071</td>\n      <td>0.278616</td>\n      <td>0.644755</td>\n      <td>...</td>\n      <td>0.243471</td>\n      <td>0.270355</td>\n      <td>0.109394</td>\n      <td>0.815672</td>\n      <td>0.245882</td>\n      <td>0.429342</td>\n      <td>31.729449</td>\n      <td>194.891310</td>\n      <td>606.347851</td>\n      <td>0.488698</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.588000</td>\n      <td>6.000000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.065000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.276000</td>\n      <td>15.000000</td>\n      <td>95.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.380000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.160000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.188000</td>\n      <td>0.000000</td>\n      <td>0.315000</td>\n      <td>0.052000</td>\n      <td>0.000000</td>\n      <td>3.706000</td>\n      <td>43.000000</td>\n      <td>266.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.540000</td>\n      <td>14.280000</td>\n      <td>5.100000</td>\n      <td>42.810000</td>\n      <td>10.000000</td>\n      <td>5.880000</td>\n      <td>7.270000</td>\n      <td>11.110000</td>\n      <td>5.260000</td>\n      <td>18.180000</td>\n      <td>...</td>\n      <td>4.385000</td>\n      <td>9.752000</td>\n      <td>4.081000</td>\n      <td>32.478000</td>\n      <td>6.003000</td>\n      <td>19.829000</td>\n      <td>1102.500000</td>\n      <td>9989.000000</td>\n      <td>15841.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset.dropna(inplace=True)\n",
    "dataset.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check if any missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().any().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "# The features are stored in X\n",
    "#pd.DataFrame(X).info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \nmean      0.104553     0.213015     0.280656     0.065425     0.312223   \nstd       0.305358     1.290575     0.504143     1.395151     0.672513   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.000000     0.420000     0.000000     0.380000   \nmax       4.540000    14.280000     5.100000    42.810000    10.000000   \n\n                5            6            7            8            9   ...  \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000  ...   \nmean      0.095901     0.114208     0.105295     0.090067     0.239413  ...   \nstd       0.273824     0.391441     0.401071     0.278616     0.644755  ...   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n75%       0.000000     0.000000     0.000000     0.000000     0.160000  ...   \nmax       5.880000     7.270000    11.110000     5.260000    18.180000  ...   \n\n                47           48           49           50           51  \\\ncount  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \nmean      0.031869     0.038575     0.139030     0.016976     0.269071   \nstd       0.285735     0.243471     0.270355     0.109394     0.815672   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.065000     0.000000     0.000000   \n75%       0.000000     0.000000     0.188000     0.000000     0.315000   \nmax      10.000000     4.385000     9.752000     4.081000    32.478000   \n\n                52           53           54           55            56  \ncount  4601.000000  4601.000000  4601.000000  4601.000000   4601.000000  \nmean      0.075811     0.044238     5.191515    52.172789    283.289285  \nstd       0.245882     0.429342    31.729449   194.891310    606.347851  \nmin       0.000000     0.000000     1.000000     1.000000      1.000000  \n25%       0.000000     0.000000     1.588000     6.000000     35.000000  \n50%       0.000000     0.000000     2.276000    15.000000     95.000000  \n75%       0.052000     0.000000     3.706000    43.000000    266.000000  \nmax       6.003000    19.829000  1102.500000  9989.000000  15841.000000  \n\n[8 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>...</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n      <td>4601.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.104553</td>\n      <td>0.213015</td>\n      <td>0.280656</td>\n      <td>0.065425</td>\n      <td>0.312223</td>\n      <td>0.095901</td>\n      <td>0.114208</td>\n      <td>0.105295</td>\n      <td>0.090067</td>\n      <td>0.239413</td>\n      <td>...</td>\n      <td>0.031869</td>\n      <td>0.038575</td>\n      <td>0.139030</td>\n      <td>0.016976</td>\n      <td>0.269071</td>\n      <td>0.075811</td>\n      <td>0.044238</td>\n      <td>5.191515</td>\n      <td>52.172789</td>\n      <td>283.289285</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.305358</td>\n      <td>1.290575</td>\n      <td>0.504143</td>\n      <td>1.395151</td>\n      <td>0.672513</td>\n      <td>0.273824</td>\n      <td>0.391441</td>\n      <td>0.401071</td>\n      <td>0.278616</td>\n      <td>0.644755</td>\n      <td>...</td>\n      <td>0.285735</td>\n      <td>0.243471</td>\n      <td>0.270355</td>\n      <td>0.109394</td>\n      <td>0.815672</td>\n      <td>0.245882</td>\n      <td>0.429342</td>\n      <td>31.729449</td>\n      <td>194.891310</td>\n      <td>606.347851</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.588000</td>\n      <td>6.000000</td>\n      <td>35.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.065000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.276000</td>\n      <td>15.000000</td>\n      <td>95.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.380000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.160000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.188000</td>\n      <td>0.000000</td>\n      <td>0.315000</td>\n      <td>0.052000</td>\n      <td>0.000000</td>\n      <td>3.706000</td>\n      <td>43.000000</td>\n      <td>266.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.540000</td>\n      <td>14.280000</td>\n      <td>5.100000</td>\n      <td>42.810000</td>\n      <td>10.000000</td>\n      <td>5.880000</td>\n      <td>7.270000</td>\n      <td>11.110000</td>\n      <td>5.260000</td>\n      <td>18.180000</td>\n      <td>...</td>\n      <td>10.000000</td>\n      <td>4.385000</td>\n      <td>9.752000</td>\n      <td>4.081000</td>\n      <td>32.478000</td>\n      <td>6.003000</td>\n      <td>19.829000</td>\n      <td>1102.500000</td>\n      <td>9989.000000</td>\n      <td>15841.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "                 0\ncount  4601.000000\nmean      0.394045\nstd       0.488698\nmin       0.000000\n25%       0.000000\n50%       0.000000\n75%       1.000000\nmax       1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4601.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.394045</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.488698</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets see unique values in our explanatory data section"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  1 has  142 unique values in 4601 rows\n",
      "Column  2 has  171 unique values in 4601 rows\n",
      "Column  3 has  214 unique values in 4601 rows\n",
      "Column  4 has  43 unique values in 4601 rows\n",
      "Column  5 has  255 unique values in 4601 rows\n",
      "Column  6 has  141 unique values in 4601 rows\n",
      "Column  7 has  173 unique values in 4601 rows\n",
      "Column  8 has  170 unique values in 4601 rows\n",
      "Column  9 has  144 unique values in 4601 rows\n",
      "Column  10 has  245 unique values in 4601 rows\n",
      "Column  11 has  113 unique values in 4601 rows\n",
      "Column  12 has  316 unique values in 4601 rows\n",
      "Column  13 has  158 unique values in 4601 rows\n",
      "Column  14 has  133 unique values in 4601 rows\n",
      "Column  15 has  118 unique values in 4601 rows\n",
      "Column  16 has  253 unique values in 4601 rows\n",
      "Column  17 has  197 unique values in 4601 rows\n",
      "Column  18 has  229 unique values in 4601 rows\n",
      "Column  19 has  575 unique values in 4601 rows\n",
      "Column  20 has  148 unique values in 4601 rows\n",
      "Column  21 has  401 unique values in 4601 rows\n",
      "Column  22 has  99 unique values in 4601 rows\n",
      "Column  23 has  164 unique values in 4601 rows\n",
      "Column  24 has  143 unique values in 4601 rows\n",
      "Column  25 has  395 unique values in 4601 rows\n",
      "Column  26 has  281 unique values in 4601 rows\n",
      "Column  27 has  240 unique values in 4601 rows\n",
      "Column  28 has  200 unique values in 4601 rows\n",
      "Column  29 has  156 unique values in 4601 rows\n",
      "Column  30 has  179 unique values in 4601 rows\n",
      "Column  31 has  128 unique values in 4601 rows\n",
      "Column  32 has  106 unique values in 4601 rows\n",
      "Column  33 has  184 unique values in 4601 rows\n",
      "Column  34 has  110 unique values in 4601 rows\n",
      "Column  35 has  177 unique values in 4601 rows\n",
      "Column  36 has  159 unique values in 4601 rows\n",
      "Column  37 has  188 unique values in 4601 rows\n",
      "Column  38 has  53 unique values in 4601 rows\n",
      "Column  39 has  163 unique values in 4601 rows\n",
      "Column  40 has  125 unique values in 4601 rows\n",
      "Column  41 has  108 unique values in 4601 rows\n",
      "Column  42 has  186 unique values in 4601 rows\n",
      "Column  43 has  136 unique values in 4601 rows\n",
      "Column  44 has  160 unique values in 4601 rows\n",
      "Column  45 has  230 unique values in 4601 rows\n",
      "Column  46 has  227 unique values in 4601 rows\n",
      "Column  47 has  38 unique values in 4601 rows\n",
      "Column  48 has  106 unique values in 4601 rows\n",
      "Column  49 has  313 unique values in 4601 rows\n",
      "Column  50 has  641 unique values in 4601 rows\n",
      "Column  51 has  225 unique values in 4601 rows\n",
      "Column  52 has  964 unique values in 4601 rows\n",
      "Column  53 has  504 unique values in 4601 rows\n",
      "Column  54 has  316 unique values in 4601 rows\n",
      "Column  55 has  2161 unique values in 4601 rows\n",
      "Column  56 has  271 unique values in 4601 rows\n",
      "Column  57 has  919 unique values in 4601 rows\n"
     ]
    }
   ],
   "source": [
    "for i in range(57):\n",
    "    print(\"Column \",i+1, \"has \",len(pd.DataFrame(X).iloc[:,i].unique()), \"unique values in 4601 rows\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our explanatory variables have a huge variations of values. Such a large continuous space can not be easily dealt with\n",
    "without some preprocessing involving discretization or scaling.\n",
    "In our case, we will discretize the data later. Why?\n",
    "Both techniques will map large continuous data to a manageable scale but the requirement of this assignment is to\n",
    "code the least general generalization and or either of its 2 variants, which are by nature not distance based algorithms.\n",
    "As such, scaling will be of no aid to us and discretization of datapoints into bins across the data( 57 columns 4600 rows, assuming all values are unique will result in an insanely large instance/hypothesis space) will make our data manageable. Infact scaling has no impact on data as the mean,std did not change post discretization (understandable as scaling just maps the values to a range while maintaining their nature)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discretization and Train-Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For discretization, the kmeans and uniform strategy explored however we went with kmeans as it kmeans as assigning by clusters features and accuracy observed was better.\n",
    "As for selecting size of the bins (trade off for reasonably sized and good accuracy), we performed following experiment\n",
    "- Calculate accuracy with bins 10-20 and Test % 20,25,30\n",
    "- Check difference of average of % test size for bin and how close difference was from 0\n",
    "- Vote across test size columns for what bin is closest.\n",
    "- Across all tests, bin size 16 fit the criteria (check score.csv file attached)\n",
    "- If result pattern are such that 2 or more values show up, take mean of bins"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "# The train-test split is implemented below with 25% of test data and 75% of train data. For 4601 datapoints, this was a good split %age\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25 , random_state= 42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "# Creating an object for KBinDiscretizer with 16 bins\n",
    "discretization = KBinsDiscretizer(n_bins = 16, encode = 'ordinal', strategy = 'kmeans')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "# The training data was preprocessed and stored in X-train\n",
    "X_train=discretization.fit_transform(X_train) # fit and transform train data to per discretization strategy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "#discretization.get_params()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "# The test data was preprocessed and stored in X-test\n",
    "X_test=discretization.transform(X_test)  # Transforming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nsince we applied fit_transform on train and only transform on test,\\nthe value ranges will be different so that test data will come as a \"surprise\" to the train.\\n'"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "since we applied fit_transform on train and only transform on test,\n",
    "the value ranges will be different so that test data will come as a \"surprise\" to the train.\n",
    "\"\"\"\n",
    "#pd.DataFrame(X_train).iloc[:,2].unique(),pd.DataFrame(X_test).iloc[:,2].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column  1 has  16 unique values in 4601 rows\n",
      "Column  2 has  16 unique values in 4601 rows\n",
      "Column  3 has  16 unique values in 4601 rows\n",
      "Column  4 has  16 unique values in 4601 rows\n",
      "Column  5 has  16 unique values in 4601 rows\n",
      "Column  6 has  16 unique values in 4601 rows\n",
      "Column  7 has  16 unique values in 4601 rows\n",
      "Column  8 has  16 unique values in 4601 rows\n",
      "Column  9 has  16 unique values in 4601 rows\n",
      "Column  10 has  16 unique values in 4601 rows\n",
      "Column  11 has  16 unique values in 4601 rows\n",
      "Column  12 has  16 unique values in 4601 rows\n",
      "Column  13 has  16 unique values in 4601 rows\n",
      "Column  14 has  16 unique values in 4601 rows\n",
      "Column  15 has  16 unique values in 4601 rows\n",
      "Column  16 has  16 unique values in 4601 rows\n",
      "Column  17 has  16 unique values in 4601 rows\n",
      "Column  18 has  16 unique values in 4601 rows\n",
      "Column  19 has  16 unique values in 4601 rows\n",
      "Column  20 has  16 unique values in 4601 rows\n",
      "Column  21 has  16 unique values in 4601 rows\n",
      "Column  22 has  16 unique values in 4601 rows\n",
      "Column  23 has  16 unique values in 4601 rows\n",
      "Column  24 has  16 unique values in 4601 rows\n",
      "Column  25 has  16 unique values in 4601 rows\n",
      "Column  26 has  16 unique values in 4601 rows\n",
      "Column  27 has  16 unique values in 4601 rows\n",
      "Column  28 has  16 unique values in 4601 rows\n",
      "Column  29 has  16 unique values in 4601 rows\n",
      "Column  30 has  16 unique values in 4601 rows\n",
      "Column  31 has  16 unique values in 4601 rows\n",
      "Column  32 has  16 unique values in 4601 rows\n",
      "Column  33 has  16 unique values in 4601 rows\n",
      "Column  34 has  16 unique values in 4601 rows\n",
      "Column  35 has  16 unique values in 4601 rows\n",
      "Column  36 has  16 unique values in 4601 rows\n",
      "Column  37 has  16 unique values in 4601 rows\n",
      "Column  38 has  16 unique values in 4601 rows\n",
      "Column  39 has  16 unique values in 4601 rows\n",
      "Column  40 has  16 unique values in 4601 rows\n",
      "Column  41 has  16 unique values in 4601 rows\n",
      "Column  42 has  16 unique values in 4601 rows\n",
      "Column  43 has  16 unique values in 4601 rows\n",
      "Column  44 has  16 unique values in 4601 rows\n",
      "Column  45 has  16 unique values in 4601 rows\n",
      "Column  46 has  16 unique values in 4601 rows\n",
      "Column  47 has  16 unique values in 4601 rows\n",
      "Column  48 has  16 unique values in 4601 rows\n",
      "Column  49 has  16 unique values in 4601 rows\n",
      "Column  50 has  16 unique values in 4601 rows\n",
      "Column  51 has  16 unique values in 4601 rows\n",
      "Column  52 has  16 unique values in 4601 rows\n",
      "Column  53 has  16 unique values in 4601 rows\n",
      "Column  54 has  16 unique values in 4601 rows\n",
      "Column  55 has  16 unique values in 4601 rows\n",
      "Column  56 has  16 unique values in 4601 rows\n",
      "Column  57 has  16 unique values in 4601 rows\n"
     ]
    }
   ],
   "source": [
    "for i in range(57):\n",
    "    print(\"Column \",i+1, \"has \",len(pd.DataFrame(X_train).iloc[:,i].unique()), \"unique values in 4601 rows\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  3450.000000  3450.000000  3450.000000  3450.000000  3450.000000   \nmean      0.725217     0.509565     1.102899     0.043478     1.022319   \nstd       1.728742     1.778238     1.902865     0.656276     1.842232   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.000000     2.000000     0.000000     1.000000   \nmax      15.000000    15.000000    15.000000    15.000000    15.000000   \n\n                5            6            7            8            9   ...  \\\ncount  3450.000000  3450.000000  3450.000000  3450.000000  3450.000000  ...   \nmean      0.826377     0.563188     0.494203     0.595362     1.052464  ...   \nstd       1.971455     1.682437     1.466192     1.708465     2.292695  ...   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n75%       0.000000     0.000000     0.000000     0.000000     1.000000  ...   \nmax      15.000000    15.000000    15.000000    15.000000    15.000000  ...   \n\n                47           48           49           50           51  \\\ncount  3450.000000  3450.000000  3450.000000  3450.000000  3450.000000   \nmean      0.182609     0.434783     1.167246     0.450725     0.946377   \nstd       1.146674     1.495119     1.603354     1.627550     1.651157   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n75%       0.000000     0.000000     2.000000     0.000000     1.000000   \nmax      15.000000    15.000000    15.000000    15.000000    15.000000   \n\n                52           53           54           55           56  \ncount  3450.000000  3450.000000  3450.000000  3450.000000  3450.000000  \nmean      0.735942     0.338841     0.320580     0.659710     1.338841  \nstd       1.575255     1.312661     0.914659     1.730502     2.056247  \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n50%       0.000000     0.000000     0.000000     0.000000     1.000000  \n75%       1.000000     0.000000     0.000000     1.000000     2.000000  \nmax      15.000000    15.000000    15.000000    15.000000    15.000000  \n\n[8 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>...</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n      <td>3450.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.725217</td>\n      <td>0.509565</td>\n      <td>1.102899</td>\n      <td>0.043478</td>\n      <td>1.022319</td>\n      <td>0.826377</td>\n      <td>0.563188</td>\n      <td>0.494203</td>\n      <td>0.595362</td>\n      <td>1.052464</td>\n      <td>...</td>\n      <td>0.182609</td>\n      <td>0.434783</td>\n      <td>1.167246</td>\n      <td>0.450725</td>\n      <td>0.946377</td>\n      <td>0.735942</td>\n      <td>0.338841</td>\n      <td>0.320580</td>\n      <td>0.659710</td>\n      <td>1.338841</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.728742</td>\n      <td>1.778238</td>\n      <td>1.902865</td>\n      <td>0.656276</td>\n      <td>1.842232</td>\n      <td>1.971455</td>\n      <td>1.682437</td>\n      <td>1.466192</td>\n      <td>1.708465</td>\n      <td>2.292695</td>\n      <td>...</td>\n      <td>1.146674</td>\n      <td>1.495119</td>\n      <td>1.603354</td>\n      <td>1.627550</td>\n      <td>1.651157</td>\n      <td>1.575255</td>\n      <td>1.312661</td>\n      <td>0.914659</td>\n      <td>1.730502</td>\n      <td>2.056247</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>...</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "data": {
      "text/plain": "                0            1            2            3            4   \\\ncount  1151.000000  1151.000000  1151.000000  1151.000000  1151.000000   \nmean      0.776716     0.587315     1.105126     0.054735     1.119027   \nstd       1.808582     1.991935     1.847744     0.750392     1.837932   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n75%       0.000000     0.000000     2.000000     0.000000     2.000000   \nmax      14.000000    15.000000    14.000000    15.000000    14.000000   \n\n                5            6            7            8            9   ...  \\\ncount  1151.000000  1151.000000  1151.000000  1151.000000  1151.000000  ...   \nmean      0.885317     0.653345     0.506516     0.661164     1.056473  ...   \nstd       2.094062     1.917128     1.516776     1.844346     2.309777  ...   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n75%       0.000000     0.000000     0.000000     0.000000     1.000000  ...   \nmax      14.000000    15.000000    13.000000    14.000000    14.000000  ...   \n\n                47           48           49           50           51  \\\ncount  1151.000000  1151.000000  1151.000000  1151.000000  1151.000000   \nmean      0.159861     0.455256     1.124240     0.395308     1.000869   \nstd       1.108303     1.561339     1.470059     1.461725     1.661063   \nmin       0.000000     0.000000     0.000000     0.000000     0.000000   \n25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n75%       0.000000     0.000000     2.000000     0.000000     2.000000   \nmax      15.000000    15.000000    10.000000    15.000000    12.000000   \n\n                52           53           54           55           56  \ncount  1151.000000  1151.000000  1151.000000  1151.000000  1151.000000  \nmean      0.720243     0.325804     0.325804     0.638575     1.376195  \nstd       1.596714     1.237397     1.013313     1.665937     2.090165  \nmin       0.000000     0.000000     0.000000     0.000000     0.000000  \n25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n50%       0.000000     0.000000     0.000000     0.000000     1.000000  \n75%       1.000000     0.000000     0.000000     1.000000     2.000000  \nmax      14.000000    15.000000    13.000000    12.000000    15.000000  \n\n[8 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n      <th>50</th>\n      <th>51</th>\n      <th>52</th>\n      <th>53</th>\n      <th>54</th>\n      <th>55</th>\n      <th>56</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>...</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n      <td>1151.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.776716</td>\n      <td>0.587315</td>\n      <td>1.105126</td>\n      <td>0.054735</td>\n      <td>1.119027</td>\n      <td>0.885317</td>\n      <td>0.653345</td>\n      <td>0.506516</td>\n      <td>0.661164</td>\n      <td>1.056473</td>\n      <td>...</td>\n      <td>0.159861</td>\n      <td>0.455256</td>\n      <td>1.124240</td>\n      <td>0.395308</td>\n      <td>1.000869</td>\n      <td>0.720243</td>\n      <td>0.325804</td>\n      <td>0.325804</td>\n      <td>0.638575</td>\n      <td>1.376195</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.808582</td>\n      <td>1.991935</td>\n      <td>1.847744</td>\n      <td>0.750392</td>\n      <td>1.837932</td>\n      <td>2.094062</td>\n      <td>1.917128</td>\n      <td>1.516776</td>\n      <td>1.844346</td>\n      <td>2.309777</td>\n      <td>...</td>\n      <td>1.108303</td>\n      <td>1.561339</td>\n      <td>1.470059</td>\n      <td>1.461725</td>\n      <td>1.661063</td>\n      <td>1.596714</td>\n      <td>1.237397</td>\n      <td>1.013313</td>\n      <td>1.665937</td>\n      <td>2.090165</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>14.000000</td>\n      <td>15.000000</td>\n      <td>14.000000</td>\n      <td>15.000000</td>\n      <td>14.000000</td>\n      <td>14.000000</td>\n      <td>15.000000</td>\n      <td>13.000000</td>\n      <td>14.000000</td>\n      <td>14.000000</td>\n      <td>...</td>\n      <td>15.000000</td>\n      <td>15.000000</td>\n      <td>10.000000</td>\n      <td>15.000000</td>\n      <td>12.000000</td>\n      <td>14.000000</td>\n      <td>15.000000</td>\n      <td>13.000000</td>\n      <td>12.000000</td>\n      <td>15.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test).describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "93e49e4a",
   "metadata": {},
   "source": [
    "# Prepping the algo's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdcb380",
   "metadata": {},
   "source": [
    "### Algorithm 4.1 implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "48629990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Algorithm 4.1 is implemented below\n",
    "# finding the least general generalisation of a given set of instances.\n",
    "def lgg(H,x): #x is instances of data, h is logical expression\n",
    "    for j in range(len(H)):\n",
    "        H[j].append(x[0][j]) # H<--X X values into H\n",
    "    #per algorithm 4.1 design (refer section 4.1 of course book)\n",
    "    while j<len(x):\n",
    "        H = lgg_conjid(H,x[j]) # Calling Alg 4.3 the LGG-conj-ID\n",
    "        j+=1\n",
    "    return H # returning the H (the logical expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb4a2d",
   "metadata": {},
   "source": [
    "### Algorithm 4.3 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "6fb34e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Algorithm 4.3 is implemented below \n",
    "def lgg_conjid(X,y): # Least General Generalisation with 2 conjunctions with internal disjunction\n",
    "    for i in range(len(X)):\n",
    "        if y[i] not in X[i]:\n",
    "            X[i].append(y[i]) # logic of Combine-ID in book\n",
    "    return X #returning the combined values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16420d",
   "metadata": {},
   "source": [
    "### Required Functions for fit and test hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "# The Hypothesis is shown as a list of list created below\n",
    "# This will be used by the algorithms for processing and store response to.\n",
    "Hypothesis = []\n",
    "i = 0\n",
    "while i<(np.shape(X)[1]):\n",
    "    Hypothesis.append([])\n",
    "    i+=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "8ea45be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used for providing train data for LGG algorithm in hypothesis space\n",
    "def training_data(a,b):\n",
    "    data_collect=[] # collecting the positives\n",
    "    [data_collect.append(a[i]) for i in range(len(a)) if(b[i]==1)]\n",
    "    h = lgg(Hypothesis,data_collect) # calling the LGG function\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1b12dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used for testing the reduced hypothesis space \n",
    "def testing_data(a):\n",
    "    pred_response = []\n",
    "    for i in range(len(a)):\n",
    "        e=0\n",
    "        for j in range(len(a[i])):\n",
    "            if a[i][j] in Hypothesis[j]:\n",
    "                e= e+1\n",
    "        pred_response.append(1) if(e==len(a[i])) else pred_response.append(0)\n",
    "    return pred_response"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Executing everything"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "HypSpa=training_data(X_train,y_train) # Generating the Hypothesis\n",
    "y_pred=testing_data(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 1.0, 5.0, 4.0, 2.0, 3.0, 6.0, 7.0, 9.0, 11.0, 8.0, 15.0], [0.0, 2.0, 3.0, 4.0, 1.0, 5.0, 10.0, 8.0, 6.0, 13.0, 7.0, 9.0, 11.0], [0.0, 5.0, 2.0, 7.0, 1.0, 4.0, 3.0, 9.0, 8.0, 6.0, 10.0, 12.0, 11.0], [0.0, 1.0, 15.0, 10.0, 4.0, 7.0, 12.0, 14.0, 3.0, 11.0, 9.0, 5.0, 2.0, 13.0, 8.0], [0.0, 2.0, 3.0, 1.0, 4.0, 9.0, 5.0, 6.0, 8.0, 7.0, 12.0, 10.0, 13.0], [0.0, 5.0, 8.0, 11.0, 6.0, 1.0, 9.0, 2.0, 4.0, 3.0, 7.0, 10.0, 12.0], [7.0, 0.0, 3.0, 2.0, 1.0, 4.0, 5.0, 8.0, 10.0, 6.0, 9.0, 11.0, 15.0, 14.0, 13.0, 12.0], [0.0, 1.0, 2.0, 3.0, 6.0, 5.0, 7.0, 11.0, 14.0, 8.0, 4.0, 12.0, 13.0, 9.0, 10.0, 15.0], [0.0, 1.0, 4.0, 2.0, 7.0, 5.0, 3.0, 6.0, 8.0, 9.0, 14.0, 12.0, 10.0, 13.0, 11.0], [0.0, 1.0, 6.0, 3.0, 9.0, 7.0, 2.0, 8.0, 12.0, 4.0, 5.0, 10.0, 11.0, 13.0, 14.0], [0.0, 4.0, 3.0, 1.0, 8.0, 7.0, 5.0, 9.0, 10.0, 2.0, 6.0, 11.0, 12.0, 13.0, 14.0, 15.0], [0.0, 1.0, 2.0, 4.0, 5.0, 3.0, 7.0, 6.0, 13.0, 8.0, 11.0, 9.0], [0.0, 4.0, 2.0, 8.0, 1.0, 10.0, 6.0, 3.0, 7.0, 5.0, 9.0, 13.0, 11.0], [0.0, 7.0, 1.0, 2.0, 6.0, 4.0, 13.0, 3.0, 8.0, 5.0, 11.0, 9.0, 10.0], [0.0, 1.0, 4.0, 2.0, 5.0, 7.0, 6.0, 9.0, 13.0, 14.0, 3.0, 11.0, 10.0, 15.0, 12.0, 8.0], [3.0, 2.0, 0.0, 1.0, 5.0, 4.0, 9.0, 6.0, 7.0, 8.0, 11.0, 13.0, 10.0, 12.0, 14.0], [0.0, 2.0, 3.0, 5.0, 4.0, 10.0, 6.0, 1.0, 9.0, 13.0, 11.0, 7.0, 8.0, 14.0, 12.0, 15.0], [0.0, 6.0, 5.0, 3.0, 4.0, 2.0, 1.0, 12.0, 11.0, 7.0, 13.0, 8.0, 10.0, 15.0, 9.0], [0.0, 2.0, 4.0, 7.0, 8.0, 1.0, 3.0, 5.0, 6.0, 9.0, 11.0, 10.0, 13.0], [0.0, 3.0, 2.0, 1.0, 11.0, 4.0, 9.0, 6.0, 12.0, 10.0, 7.0, 5.0, 8.0, 14.0, 15.0, 13.0], [0.0, 3.0, 2.0, 4.0, 5.0, 1.0, 6.0, 8.0, 7.0, 10.0, 9.0, 15.0], [0.0, 4.0, 1.0, 3.0, 9.0, 12.0, 8.0, 7.0, 2.0, 11.0, 10.0, 14.0, 15.0, 5.0, 13.0], [0.0, 4.0, 5.0, 2.0, 1.0, 3.0, 7.0, 6.0, 9.0, 11.0, 12.0, 8.0, 13.0, 10.0, 15.0], [0.0, 1.0, 2.0, 4.0, 3.0, 9.0, 7.0, 5.0, 10.0, 11.0, 8.0, 15.0, 12.0, 13.0], [0.0, 1.0, 4.0, 2.0], [0.0, 1.0, 2.0, 5.0, 3.0, 4.0], [0.0], [0.0, 1.0, 3.0, 4.0, 2.0, 14.0, 7.0, 15.0, 6.0], [0.0, 1.0, 3.0], [0.0, 2.0, 1.0, 3.0], [0.0, 1.0, 4.0], [0.0, 3.0], [0.0, 3.0, 1.0, 2.0, 6.0, 4.0, 5.0], [0.0, 6.0, 1.0, 3.0, 2.0], [0.0, 1.0, 2.0, 3.0, 8.0, 4.0], [0.0, 4.0, 1.0, 2.0, 6.0, 3.0, 5.0], [0.0, 11.0, 5.0, 6.0, 1.0, 2.0, 3.0, 7.0, 4.0, 8.0], [0.0, 3.0, 2.0, 1.0, 8.0, 6.0, 7.0, 5.0], [0.0, 1.0, 3.0, 2.0, 5.0, 4.0], [0.0, 4.0, 1.0, 3.0, 2.0, 5.0, 9.0, 7.0], [0.0, 1.0], [0.0, 1.0], [0.0, 3.0, 1.0, 2.0, 4.0, 5.0], [0.0, 2.0, 1.0, 5.0], [0.0, 2.0, 1.0, 3.0, 7.0, 5.0, 4.0], [0.0, 1.0, 3.0, 2.0, 5.0], [0.0, 1.0, 5.0, 2.0], [0.0, 1.0, 2.0], [0.0, 1.0, 6.0, 3.0, 5.0, 4.0, 7.0, 8.0, 2.0, 10.0, 9.0], [0.0, 1.0, 2.0, 3.0, 5.0, 4.0, 6.0, 11.0, 7.0, 13.0, 15.0, 8.0], [0.0, 2.0, 3.0, 1.0, 7.0, 9.0, 6.0, 8.0, 5.0, 10.0, 4.0, 13.0], [6.0, 3.0, 0.0, 5.0, 7.0, 1.0, 2.0, 4.0, 8.0, 10.0, 9.0, 11.0, 12.0], [0.0, 15.0, 3.0, 1.0, 2.0, 5.0, 4.0, 6.0, 12.0, 7.0, 9.0, 13.0, 8.0, 11.0, 10.0, 14.0], [0.0, 2.0, 1.0, 5.0, 4.0, 11.0, 9.0, 6.0, 12.0, 3.0, 10.0, 8.0, 7.0, 15.0], [0.0, 1.0, 2.0, 7.0, 3.0, 10.0, 6.0, 8.0, 5.0, 13.0, 11.0, 4.0, 12.0, 14.0, 9.0, 15.0], [0.0, 1.0, 2.0, 10.0, 12.0, 3.0, 5.0, 4.0, 9.0, 11.0, 13.0, 7.0, 6.0, 8.0, 14.0, 15.0], [0.0, 4.0, 1.0, 3.0, 9.0, 2.0, 11.0, 5.0, 6.0, 8.0, 7.0, 14.0, 10.0, 12.0, 13.0, 15.0]]\n"
     ]
    }
   ],
   "source": [
    "print(HypSpa) # can use the global Hypothesis too though. These should be the literals but we ran out of time and mind to use column name to produce the actual rules in words. that would have been fun."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performance Criteria\n",
    "After training is done, we calculate how good our model performed.\n",
    "We will calculate accuracy as the metric to assess our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7454387489139879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#reshaping y_pred and finding accuracy\n",
    "y_pred=np.array(y_pred).reshape(len(y_test),1)\n",
    "print(accuracy_score(y_pred,y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
